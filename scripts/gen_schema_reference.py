#!/usr/bin/env python3
"""Generate agents/schema-reference.md from LinkML schemas.

This script reads the facility and IMAS DD schemas and produces a
Markdown reference file that agents can read for graph context. The
output is gitignored and regenerated during ``uv sync``.

Usage:
    uv run python scripts/gen_schema_reference.py
    uv run python scripts/gen_schema_reference.py --force
"""

from __future__ import annotations

import sys
from pathlib import Path


def get_project_root() -> Path:
    return Path(__file__).parent.parent


def generate_schema_reference(force: bool = False) -> Path:
    """Generate agents/schema-reference.md from LinkML schemas.

    Returns the path to the generated file.
    """
    project_root = get_project_root()
    output_file = project_root / "agents" / "schema-reference.md"
    schemas_dir = project_root / "imas_codex" / "schemas"

    # Freshness check: skip if output is newer than all schema sources
    schema_files = [
        schemas_dir / "facility.yaml",
        schemas_dir / "common.yaml",
        schemas_dir / "imas_dd.yaml",
    ]
    existing_schemas = [f for f in schema_files if f.exists()]

    if not existing_schemas:
        print("[gen-schema-ref] No schema files found, skipping")
        return output_file

    if output_file.exists() and not force:
        output_mtime = output_file.stat().st_mtime
        if all(f.stat().st_mtime <= output_mtime for f in existing_schemas):
            print(f"[gen-schema-ref] Up to date: {output_file}")
            return output_file

    # Import schema introspection (requires generated models to exist)
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

    from imas_codex.graph.schema import GraphSchema

    facility_schema = GraphSchema(schemas_dir / "facility.yaml")
    dd_schema = GraphSchema(schemas_dir / "imas_dd.yaml")

    # Merge node labels (DD schema adds IMASPath, DDVersion, etc.)
    all_labels = sorted(set(facility_schema.node_labels + dd_schema.node_labels))

    # Merge vector indexes
    seen_indexes: dict[str, tuple[str, str]] = {}
    for idx_name, label, prop in facility_schema.vector_indexes:
        seen_indexes[idx_name] = (label, prop)
    for idx_name, label, prop in dd_schema.vector_indexes:
        if idx_name not in seen_indexes:
            seen_indexes[idx_name] = (label, prop)

    # Merge relationship types
    all_rels = sorted(
        set(facility_schema.relationship_types + dd_schema.relationship_types)
    )

    # Merge enums
    all_enums: dict[str, list[str]] = {}
    all_enums.update(dd_schema.get_enums())
    all_enums.update(facility_schema.get_enums())

    # Choose primary schema for slot introspection
    def get_schema_for(label: str) -> GraphSchema:
        if label in facility_schema.node_labels:
            return facility_schema
        return dd_schema

    # ---- Build markdown ----
    lines: list[str] = []

    lines.append("# Graph Schema Reference")
    lines.append("")
    lines.append("<!-- AUTO-GENERATED by scripts/gen_schema_reference.py -->")
    lines.append(
        "<!-- DO NOT EDIT — regenerate with: uv run python scripts/gen_schema_reference.py --force -->"
    )
    lines.append("")
    lines.append(
        "This file is the auto-generated graph schema reference derived from the "
        "LinkML schemas (`imas_codex/schemas/`). It is rebuilt during `uv sync` "
        "and gitignored. Use `get_graph_schema()` MCP tool for runtime introspection."
    )

    # ---- Vector Indexes ----
    lines.append("")
    lines.append("## Vector Indexes")
    lines.append("")
    lines.append("Available for `semantic_search(text, index, k)`:")
    lines.append("")
    lines.append("| Index | Node Label | Property | Content |")
    lines.append("|-------|-----------|----------|---------|")
    for idx_name in sorted(seen_indexes):
        label, prop = seen_indexes[idx_name]
        schema = get_schema_for(label)
        desc = schema.get_class_description(label) or ""
        # Truncate long descriptions
        short_desc = desc.split(".")[0].strip() if desc else label
        if len(short_desc) > 60:
            short_desc = short_desc[:57] + "..."
        lines.append(f"| `{idx_name}` | {label} | {prop} | {short_desc} |")

    # ---- Node Labels ----
    lines.append("")
    lines.append("## Node Labels")
    lines.append("")
    lines.append(f"{len(all_labels)} node types in the graph.")
    lines.append("")

    for label in all_labels:
        schema = get_schema_for(label)
        desc = schema.get_class_description(label)
        slots = schema.get_all_slots(label)
        private_slots = set(schema.get_private_slots(label))
        rels_from = schema.get_relationships_from(label)

        lines.append(f"### {label}")
        lines.append("")
        if desc:
            # Take first paragraph only
            first_para = desc.split("\n\n")[0].replace("\n", " ").strip()
            if len(first_para) > 200:
                first_para = first_para[:197] + "..."
            lines.append(first_para)
            lines.append("")

        # Properties table
        lines.append("| Property | Type | Flags |")
        lines.append("|----------|------|-------|")
        for slot_name, info in slots.items():
            slot_type = info.get("type", "string")
            # Skip relationship slots — they appear in relationships section
            if info.get("relationship"):
                continue
            flags = []
            if info.get("identifier"):
                flags.append("**ID**")
            if info.get("required"):
                flags.append("required")
            if info.get("multivalued"):
                flags.append("list")
            if slot_name in private_slots:
                flags.append("private")
            flag_str = ", ".join(flags) if flags else ""
            lines.append(f"| `{slot_name}` | {slot_type} | {flag_str} |")

        # Outgoing relationships
        if rels_from:
            lines.append("")
            lines.append("**Relationships:**")
            for rel in rels_from:
                multi = " (many)" if rel.multivalued else ""
                lines.append(f"- `-[:{rel.cypher_type}]->` {rel.to_class}{multi}")

        lines.append("")

    # ---- Relationship Types ----
    lines.append("## Relationship Types")
    lines.append("")
    lines.append(
        f"{len(all_rels)} relationship types: " + ", ".join(f"`{r}`" for r in all_rels)
    )
    lines.append("")

    # ---- Enums ----
    lines.append("## Enums")
    lines.append("")
    for enum_name in sorted(all_enums):
        values = all_enums[enum_name]
        values_str = ", ".join(f"`{v}`" for v in values)
        lines.append(f"**{enum_name}:** {values_str}")
        lines.append("")

    content = "\n".join(lines) + "\n"
    output_file.write_text(content)
    print(
        f"[gen-schema-ref] Generated {output_file} ({len(all_labels)} labels, {len(seen_indexes)} indexes)"
    )
    return output_file


if __name__ == "__main__":
    force = "--force" in sys.argv
    generate_schema_reference(force=force)
